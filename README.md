# Smart Resume & Job Matcher

## Overview

This project implements an **AI-powered Resume and Job Matching System** based on **semantic embeddings and AI-driven reasoning**.
The system compares a candidate CV (PDF) with a job offer (text input) and outputs:

- A **match percentage**
- A **3-level verdict**:
  - ‚úÖ Postuler (‚â• 70%)
  - ‚ö†Ô∏è √Ä tenter / Adapter le CV (50‚Äì70%)
  - ‚ùå Pas prioritaire (< 50%)
- An **AI-based explanation** including:
  - Alignment reasoning
  - Identified gaps
  - Actionable advice for the candidate

The goal is to go beyond keyword matching and rely on **language understanding** through embeddings.

---

## How AI Is Used in This Project

### 1. Semantic Understanding (Core AI Component)

- CVs and job offers are encoded using **Ollama embeddings** (`nomic-embed-text`)
- These embeddings capture:
  - Skills
  - Experience
  - Education
  - Contextual meaning
- Matching is performed using **semantic similarity**, not exact wording

‚û°Ô∏è Structured information (skills, experience, etc.) is **implicitly captured** in the embedding space rather than explicitly extracted into JSON fields.

---

### 2. AI-Driven Explanation Layer

The explanation for each match is **AI-driven but deterministic**:

- The **reasoning is powered by LLM embeddings**
- The **presentation is rule-based** for:
  - Speed
  - Stability
  - No hallucinations

This design choice ensures:
- Clear and consistent explanations
- Fast inference suitable for an interactive interface
- Reliable outputs for academic evaluation

---

## Project Structure

```
.
‚îú‚îÄ‚îÄ CV/                         # Input CVs (PDF only)
‚îú‚îÄ‚îÄ offres/                     # Job offers (.txt files)
‚îú‚îÄ‚îÄ db/                         # Chroma vector databases
‚îú‚îÄ‚îÄ app.py                      # Streamlit interface
‚îú‚îÄ‚îÄ ingestion_pipeline.py       # Vector DB creation (CVs & offers)
‚îú‚îÄ‚îÄ single_match_fast.py        # Fast CV ‚Üî offer matching logic
‚îú‚îÄ‚îÄ embeddings_ollama.py        # Ollama embedding wrapper
‚îú‚îÄ‚îÄ explain_rules.py            # Deterministic explanation logic
‚îú‚îÄ‚îÄ ollama_chat.py              # Ollama API interface (optional LLM usage)
‚îú‚îÄ‚îÄ match_pipeline.py           # Matching orchestration
‚îú‚îÄ‚îÄ llm_explain.py              # (Optional) LLM explanation experiments
‚îú‚îÄ‚îÄ llm_structuring.py          # (Optional) Structured extraction experiments
‚îú‚îÄ‚îÄ archive/                    # Previous or experimental pipelines
‚îî‚îÄ‚îÄ README.md
```

---


## How to Run the Project

### 1. Requirements

- Python 3.10+
- Ollama installed and running
- Ollama model installed:
```bash
ollama pull nomic-embed-text
```

---

### 2. Build the Vector Databases (once)

```bash
python ingestion_pipeline.py
```

This creates:
- CV embeddings
- Job offer embeddings
- Stored in ChromaDB (`db/`)

---

### 3. Run a Match in Terminal (No UI)

```bash
python single_match_fast.py
```

Outputs:
- Match %
- Verdict
- AI explanation

---

### 4. Run the Streamlit Interface

```bash
streamlit run app.py
```

Interface allows:
- Uploading a CV (PDF)
- Pasting or uploading a job offer
- Instant match result and explanation

---

## Output Example

```
Match %
75.9%
Verdict : ‚úÖ Postuler
üß† Analyse IA
‚úÖ Match: comp√©tences communes d√©tect√©es (ai, data, power bi).
‚úÖ Match: missions et exp√©riences globalement compatibles selon l‚Äôanalyse s√©mantique.
‚úÖ Match: score de similarit√© √©lev√© (75.9%).
‚ö†Ô∏è Gap: comp√©tences attendues non mentionn√©es (python).
üéØ Conseil: ajouter ces comp√©tences ou projets associ√©s dans le CV.
```

---

## Authors / Notes

This project was designed as an academic AI system emphasizing **semantic understanding, explainability, and engineering trade-offs** rather than pure generative output.

DIA-3

Nour AFFES

Thomas VALESI

Chlo√© de WILDE
